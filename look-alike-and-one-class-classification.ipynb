{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Investment customer quality and look alike analysis\n\n#### What is look-alike\nLook-alike modeling is a process that identifies people who has similar feature or just look/act like the target audiences. It's commonly used in marketing to identify prospect who has similar behavior pattern as targeting clients. \n\n#### How to perform look-alike\n\n1. Always understand the goal, best customers may have different definition based on the needs and business model. For example, in this case the best customers could be either the one who purchased multiple products and has deeper engagement with the entity, or simply signed contract with the business and paid the fixed service fee.\n2. Understand the “best customer” segment and define commonalities. These traits may include anything from household income, balance with the firm, engagement to the business, or activity on different channel / platforms.\n3. Once we know how \"best customer\" look like, we can dentify all customers within the expansive database who share the same characteristics as the best customers, and try to develop relationship with them and turn them to real \"best customers\". \n\nLook-alike could be converted to traditional binary classification if the not-alike is obtainable, or anormly detection (one class classification) when the rest not look-alike minority shows significant different as look-alike. "},{"metadata":{},"cell_type":"markdown","source":"### Pre-processing\nOther than cleaning and imputing missing data, random undersample (at this time just for reduce data size) and scaling is performed"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"# remove missing value\ndef mis_val_10_del(df):\n    mis_val = df.columns[df.isnull().any()].tolist()\n    print ('No. of Variables with missing value: ', len(mis_val))\n    print(df.shape)\n    mis=  pd.DataFrame(pd.Series(mis_val), columns=['Var'])\n    mis['PTC']=[100*(sum(df[i].isnull())/df.shape[0]) for i in mis_val]\n    print (mis)\n    threshold = input ('Threshold for deleteing record with missing value (input 0-100: recommend <10%):  ')\n    for i in mis_val:\n        if 100*(sum(df[i].isnull())/df.shape[0])<int(threshold):\n            df.dropna(inplace= True, subset = [i])\n    print('Rest variables with more than ', threshold, 'precentage of missing data as : ', \n          df.columns[df.isnull().any()].tolist(), 'current df shape: ', df.shape)\n    \n# or if want to fill missing value\n# numerical\n# df.fillna(df.mean()) # df.fillna(df.median())\n# categorical \n# df[df.columns.intersection(list(df.dtypes[df.dtypes == np.object].index))].apply(lambda x: x.fillna(x.value_counts().index[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Undersampling\nimport imblearn\nfrom imblearn.under_sampling import RandomUnderSampler\nX = dfpo.drop(columns = ['Accept'])\ny = dfpo['Accept']\ny.value_counts() \n# imbalanced data with huge size, reduce size to PC friendly\nundersample = RandomUnderSampler(sampling_strategy=0.5)\n# fit and apply the transform\nX_over, y_over = undersample.fit_resample(X, y)\n# summarize class distribution\ny_over.value_counts()\n\n# Scale dataset\nimport pandas as pd\nimport numpy as np\nNum_features=X_over.select_dtypes(include=[np.number]).columns\nNum_features\n# Scaler only on numerical data (there is no benefit to scale binary data)\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler() \nX_over[Num_features]=scaler.fit_transform(X_over[Num_features])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### For confidential reason, raw data has already been scaled thus would not repeat normalizing the data in following analysis."},{"metadata":{},"cell_type":"markdown","source":"## Preparing\n\n- Feature Selection and Correlation/Association analysis\n- Encode"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndf = pd.read_csv('/kaggle/input/invst-target/referral_categ_undersamp_scaled.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Measure of Association\nTechnically, association refers to any relationship between two variables, whereas correlation is often used to refer only to a linear relationship between two variables. Here I found calculate correlation after one hot encode categorical data could expend data size significantly also would not solve scale and order issues, thus decided to go after measure of association with dython package. \n\nIn the [Dython](http://shakedzy.xyz/dython/modules/nominal/) package, numerical and categorical variables are treated accordingly: \n* Pearson's R for continuous-continuous cases \n* Correlation Ratio for categorical-continuous cases \n* Cramer's V or Theil's U for categorical-categorical cases\n\nCramer's V:based on Pearson's chi-squared statistic, measure of association between two nominal variables, giving a value between 0 and +1 (inclusive). "},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install dython\nimport numpy as np\nimport dython\nfrom dython.model_utils import roc_graph\nfrom dython.nominal import associations\nimport matplotlib.pyplot as plt\ndef associations_example():\n    associations(df, nominal_columns=list(df.dtypes[df.dtypes == np.object].index))\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"]=20,20\nassociations_example()\n\nassoc = associations(df.drop(columns = ['ID']), nominal_columns=list(df.dtypes[df.dtypes == np.object].index))\n#ID is row number\nass_corr = assoc['corr']\n# Variables with most relationship to Accept as the response\npd.DataFrame(ass_corr['ACCEPT'].sort_values(ascending=False)).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we notice, Estimated total asset, estimated total deposit, estimated stock/fund etc all have similar color, meaning all estimated variables are strongly correlated (may came from one source), we are wondering if those variables belong to a cluster, if so, what else variables could be clustered to one cluster? Below we use hierarchical clustering to determine which columns belongs to which cluster."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A clusterred correlation matrix\nimport scipy\nimport scipy.cluster.hierarchy as sch\n\nX = df.corr().values\nd = sch.distance.pdist(X)   # vector of ('55' choose 2) pairwise distances\nL = sch.linkage(d, method='complete')\nind = sch.fcluster(L, 0.5*d.max(), 'distance')\ncolumns = [df.columns.tolist()[i] for i in list((np.argsort(ind)))]\ndf_rein = df.reindex(columns, axis=1)\ndef plot_corr(df,size=10):\n    '''Plot a graphical correlation matrix for a dataframe.\n\n    Input:\n        df: pandas DataFrame\n        size: vertical and horizontal size of the plot'''\n    \n    %matplotlib inline\n    import matplotlib.pyplot as plt\n\n    # Compute the correlation matrix for the received dataframe\n    corr = df.corr()\n    \n    # Plot the correlation matrix\n    fig, ax = plt.subplots(figsize=(size, size))\n    cax = ax.matshow(corr, cmap='RdYlGn')\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90);\n    plt.yticks(range(len(corr.columns)), corr.columns);\n    \n    # Add the colorbar legend\n    cbar = fig.colorbar(cax, ticks=[-1, 0, 1], aspect=40, shrink=.8)\nplot_corr(df_rein, size=18)\n\n# Other than the estimated varaibles, loan seemed to be 1 cluster, and the rest balances belongs to another cluster.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(ass_corr['ACCEPT'].sort_values(ascending=False)).tail(10)\n# if set 0.05 as threshold, below variables may not have impact on the Acceptance of investment product. \n# in other word not impact on the definition of being 'best customers'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature Selection\nKnowing that we have strongly associated variables, no significatn association variables, also variables with strong interactions, it would be valuable to select only related feature (and look into dimension reduction in following analysis). \n\nHere I would highly recommend spend some time in this article from Dr. Brownlee\nhttps://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/\nAs the inputs here a combination of numerical and categorical, output is categorical, ANOVA: f_classif(), Chi-squared, Mutual information: mutual_info_classif()  would be better statistical measures for filter-based feature selection."},{"metadata":{"trusted":true},"cell_type":"code","source":"dfc = df.copy()\n# encode categorical variables\ndf.replace({\"Y\":1, \"N\":0}, inplace = True)\ndf.select_dtypes(include=['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['FP_CATG'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fstprd = pd.get_dummies(df['FP_CATG']) \ndf = df.merge(fstprd[['SVNG', 'EQTY', 'RET','INVST', 'CD', 'MM']], left_index=True, right_index=True)\ndf.drop(columns=['ID', 'CHANNEL', 'FP_CATG'], inplace = True)\n# check if still object \nprint(df.select_dtypes(include=['object']).columns)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n\nX=df.drop(columns = ['ACCEPT'])\nX_indices = np.arange(X.shape[-1])\ny=df['ACCEPT']\nplt.figure(1)\nplt.clf()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, stratify=y, random_state=10)\nselector = SelectKBest(f_classif, k=X.shape[-1])\nselector.fit(X_train, y_train)\nscores = -np.log10(selector.pvalues_)\nscores /= scores.max()\n\nplt.bar(X_indices - .45, scores, width=.2,\n        label=r'Univariate score ($-Log(p_{value})$)')\n\n# Compare to the weights of an SVM\nclf = make_pipeline(MinMaxScaler(), LinearSVC())\nclf.fit(X_train, y_train)\nprint('Classification accuracy without selecting features: {:.3f}'\n      .format(clf.score(X_test, y_test)))\n\nsvm_weights = np.abs(clf[-1].coef_).sum(axis=0)\nsvm_weights /= svm_weights.sum()\n\nplt.bar(X_indices - .25, svm_weights, width=.2, label='SVM weight')\n\nclf_selected = make_pipeline(\n        SelectKBest(f_classif, k='all'), MinMaxScaler(), LinearSVC()\n)\nclf_selected.fit(X_train, y_train)\nprint('Classification accuracy after univariate feature selection: {:.3f}'\n      .format(clf_selected.score(X_test, y_test)))\n\nsvm_weights_selected = np.abs(clf_selected[-1].coef_).sum(axis=0)\nsvm_weights_selected /= svm_weights_selected.sum()\n\nplt.bar(X_indices[selector.get_support()] - .05, svm_weights_selected,\n        width=.2, label='SVM weights after selection')\n\n\nplt.title(\"Comparing feature selection\")\nplt.xlabel('Feature number')\nplt.yticks(())\nplt.axis('tight')\nplt.legend(loc='upper right')\nplt.show()\n# k from 35 to len of total dataset all same","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fs= pd.concat([pd.Series(X.columns), round(pd.Series(selector.scores_),0), round(pd.Series(selector.pvalues_),5)], axis=1)\nfs.columns = [\"Val\",\"F_score\",\"P-value\"]\nfs.sort_values(by=['F_score'], ascending = False)\n# F value < 50 or P value >0.05, consider not important features\n# result similar to correlation (association)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"remove unimportant features\nEither by threshold or business insights"},{"metadata":{},"cell_type":"markdown","source":"## One-class classification\nOutlier detection with imbalanced data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.svm import OneClassSVM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(columns = ['ACCEPT'])\ny = df['ACCEPT']\nprint(y.value_counts())\n# imbalanced data\n\n# split into train/test sets\ntrainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrainX = scaler.fit_transform(trainX)\ntestX = scaler.transform(testX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Treat Referred (minority) as outliers\nprint(trainy.value_counts())\n# define outlier detection model\nmodel = OneClassSVM(gamma='scale', nu=0.01)\n# fit on majority class\ntrainX = trainX[trainy==0]\nmodel.fit(trainX)\n# detect outliers in the test set\nyhat = model.predict(testX)\n# mark inliers 1, outliers -1 as 0 are normal and majority\ntesty[testy == 1] = -1\ntesty[testy == 0] = 1\n# calculate score\nscore_u_n = f1_score(testy, yhat, pos_label=-1)\nscore_u_p = f1_score(testy, yhat, pos_label=1)\nprint('F1 Score:',round(score_u_n,4),'(n)',round(score_u_p,3),'(p)')\n# calculate score\nscore = f1_score(testy, yhat, pos_label=-1)\nprint('F1 Score: %.3f' % score)\n# care about negative, 0.305(n) not high as expected\n# non investment cutomers have wider range and contains outlier, treat non-referred (majority) as outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Treat non-referred (majority) as outliers\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline\nfrom numpy import mean\n\n# define over/under strategy\nover = SMOTE(sampling_strategy = 1)\nsteps = [('o', over)]\npipeline = Pipeline(steps = steps)\n# fit and apply the transform\nX_over, y_over = pipeline.fit_resample(trainX, trainy)\n# summarize class distribution\nprint(y_over.value_counts())\n# define outlier detection model\nmodel_u = OneClassSVM(gamma='scale', nu=0.01)\n# fit on majority class (since we undersampled 0s, 1 are clean and consideredoneclass as normal majority)\ntrainX_u = X_over[y_over==1]\nmodel_u.fit(trainX_u)\n# detect outliers in the test set\nyhat = model_u.predict(testX)\n# mark inliers 1, outliers -1 (minority as 1, potential 0s as -1)\ntesty[testy == 1] = 1\ntesty[testy == 0] = -1\n# calculate score\nscore_u_n = f1_score(testy, yhat, pos_label=-1)\nscore_u_p = f1_score(testy, yhat, pos_label=1)\nprint('F1 Score:',round(score_u_n,4),'(n)',round(score_u_p,3),'(p)')\n# calculate score\nscore = f1_score(testy, yhat, pos_label=-1)\nprint('F1 Score: %.3f' % score)\n# with over sample, positive (referrals) predict accuracy increased to 0.489(p) yet precision reduced significantly","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One class classification is used to detect outliers but here majority (not referred or not yet accepted referrals) is not a clean set. \nResampling changed the referral/rest proportion thus could not perform well with testing set.\nSee if there is any boundary between referral and rest (combinition of future referral and true non-referals)."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport numpy as np\npca = PCA()\npca.fit(trainX)\nnp.cumsum(pca.explained_variance_ratio_)\n# pca would not show clear difference in 3d graph","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}